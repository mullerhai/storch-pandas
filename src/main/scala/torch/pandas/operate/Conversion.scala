package torch.pandas.operate

/*
 * torch -- Data frames for Java
 * Copyright (c) 2014, 2015 IBM Corp.
 *
 * This program is free software: you can redistribute it and/or modify
 * it under the terms of the GNU General Public License as published by
 * the Free Software Foundation, either version 3 of the License, or
 * (at your option) any later version.
 *
 * This program is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 * GNU General Public License for more details.
 *
 * You should have received a copy of the GNU General Public License
 * along with this program.  If not, see <http://www.gnu.org/licenses/>.
 */

import java.lang.Boolean as JBoolean
import java.lang.Double as JDouble
import java.lang.IllegalArgumentException
import java.lang.Long as JLong
import java.lang.Number as JNumber
import java.lang.String as JString // Import specific Java types
// Import necessary Java classes that are still used (e.g., Date, Class, SimpleDateFormat, DateFormat)
import java.text.DateFormat
import java.text.ParsePosition
import java.text.SimpleDateFormat
import java.util.Arrays as JArrays
import java.util.Date
import java.util.List as JList
import java.util.Map as JMap
import java.util.Set as JSet // Import specific Java types with aliases if needed

import scala.collection.immutable.TreeSet
// Import necessary Scala collections
import scala.collection.mutable
import scala.collection.mutable.ListBuffer
import scala.jdk.CollectionConverters.* // For converting Java collections if needed

import torch.DataFrame
import torch.DataFrame.Function
import torch.DataFrame.NumberDefault
import torch.DataFrame.NumberDefault.DOUBLE_DEFAULT
import torch.DataFrame.NumberDefault.LONG_DEFAULT

object Conversion:

  // Use a private var for the mutable static field
  private var dummyVariableMaxLen: Int = 8

  def getDummyVariableMaxLen(): Int = dummyVariableMaxLen

  /** Set the Max length of dummy part (after the $ sign) of the column
    * (variable) names generated by <pre>toModelMatrix</pre> Observe that the
    * final name can actually become longer to avoid non-unique variable names
    * which is a requirement
    *
    * @param maxLen
    *   set to negative value for no limit
    */
  def setDummyVariableMaxLen(maxLen: Int): Unit = dummyVariableMaxLen = maxLen

  /** Converts columns in the DataFrame to appropriate types based on content.
    * Uses LONG_DEFAULT for number conversion and no NA string.
    *
    * @param df
    *   The DataFrame to convert.
    * @tparam V
    *   The type of the values in the DataFrame.
    */
  def convert[V](df: DataFrame[V]): Unit =
    convert(df, NumberDefault.LONG_DEFAULT, null) // Pass null for naString

  /** Converts columns in the DataFrame to appropriate types based on content
    * and specified defaults.
    *
    * @param df
    *   The DataFrame to convert.
    * @param numDefault
    *   The default number type to prioritize (LONG or DOUBLE).
    * @param naString
    *   An optional string representation of NA values.
    * @tparam V
    *   The type of the values in the DataFrame.
    * @throws IllegalArgumentException
    *   if numDefault contains an illegal value.
    */
  def convert[V](
      df: DataFrame[V],
      numDefault: NumberDefault,
      naString: String | Null,
  ): Unit = {
    // Use mutable.HashMap for conversions map
    val conversions = mutable.HashMap[Int, Function[V, ?]]()
    val converters: List[Function[V, ?]] = numDefault match {
      case NumberDefault.LONG_DEFAULT =>
        // Use Scala List instead of Arrays.asList
        List(
          new LongConversion[V](),
          new DoubleConversion[V](),
          new BooleanConversion[V](),
          new DateTimeConversion[V](),
        )
      case NumberDefault.DOUBLE_DEFAULT =>
        // Use Scala List instead of Arrays.asList
        List(
          new DoubleConversion[V](),
          new LongConversion[V](),
          new BooleanConversion[V](),
          new DateTimeConversion[V](),
        )
      case _ => throw new IllegalArgumentException(
          "Number default contains an Illegal value",
        )
    }

    val naConverter = new NAConversion[V](naString)
    val rows = df.length // Assuming length() is row count
    val cols = df.size // Assuming size() is column count

    // find conversions
    for (c <- 0 until cols)
      // Use Scala's exists or find for cleaner check
      converters.find(conv =>
        // Check if all values in the column can be converted by this converter
        (0 until rows).forall { r =>
          val value = df.get(r, c)
          // A value is convertible if conv.apply(value) is not null OR
          // if it is null, it must be convertible by the NA converter (i.e., it's the NA string)
          conv.apply(value.asInstanceOf[V]) != null ||
          naConverter.apply(value.asInstanceOf[V]) != null
        },
      ).foreach(conv =>
        // If a suitable converter is found, add it to the map
        conversions.put(c, conv),
      )

    // apply conversions
    convert(df, conversions.toMap, naString) // Convert mutable map to immutable for the next call
  }

  /** Converts columns in the DataFrame to specified types.
    *
    * @param df
    *   The DataFrame to convert.
    * @param columnTypes
    *   An array of Class objects specifying the target type for each column.
    * @tparam V
    *   The type of the values in the DataFrame.
    */
  // @SafeVarargs // Annotation not needed in Scala
  def convert[V](df: DataFrame[V], columnTypes: Class[? <: V]*): Unit = {
    // Use mutable.HashMap for conversions map
    val conversions = mutable.HashMap[Int, Function[V, ?]]()
    for (i <- 0 until columnTypes.length) {
      val cls = columnTypes(i)
      if (cls != null) {
        val conv: Function[V, ?] | Null =
          if (classOf[Date].isAssignableFrom(cls)) new DateTimeConversion[V]()
          else if (classOf[JBoolean].isAssignableFrom(cls))
            new BooleanConversion[V]() // Use JBoolean for java.lang.Boolean
          else if (classOf[JLong].isAssignableFrom(cls)) new LongConversion[V]() // Use JLong for java.lang.Long
          else if (classOf[JNumber].isAssignableFrom(cls))
            new DoubleConversion[V]() // Use JNumber for java.lang.Number
          else if (classOf[JString].isAssignableFrom(cls))
            new StringConversion[V]() // Use JString for java.lang.String
          else null // No suitable converter found

        if (conv != null) conversions.put(i, conv)
      }
    }
    convert(df, conversions.toMap, null) // Convert mutable map to immutable, pass null for naString
  }

  /** Applies specified conversion functions to columns in the DataFrame.
    *
    * @param df
    *   The DataFrame to convert.
    * @param conversions
    *   A Map from column index to the Function to apply.
    * @param naString
    *   An optional string representation of NA values.
    * @tparam V
    *   The type of the values in the DataFrame.
    */
  // @SuppressWarnings("unchecked") // Not needed in Scala with proper typing/casting
  def convert[V](
      df: DataFrame[V],
      conversions: Map[Int, Function[V, ?]],
      naString: String | Null,
  ): Unit = {
    val rows = df.length // Assuming length() is row count
    val cols = df.size // Assuming size() is column count
    val naConverter = new NAConversion[Any](naString)

    for (c <- 0 until cols) {
      // Use get from Scala Map which returns Option
      val convOption = conversions.get(c)

      for (r <- 0 until rows) {
        val originalValue = df.get(r, c)
        val convertedValue: Any = convOption match {
          case Some(conv) =>
            // Apply the specific converter if found
            conv.apply(originalValue.asInstanceOf[V]) // Cast result to V or Null
          case None =>
            // If no specific converter, apply the NA converter
            naConverter.apply(originalValue)
        }
        df.set(r, c, convertedValue.asInstanceOf[V]) // Set the converted value (might be null)
      }
    }
  }

  /** Converts the DataFrame to a 2D double array model matrix.
    *
    * @param df
    *   The DataFrame to convert.
    * @param fillValue
    *   The value to fill NA/null values with.
    * @tparam V
    *   The type of the values in the DataFrame.
    * @return
    *   A 2D double array.
    */
  def toModelMatrix[V](
      df: DataFrame[V],
      fillValue: Double,
  ): Array[Array[Double]] = toModelMatrixDataFrame(df).fillna(fillValue)
    .toArray(classOf[Array[Array[Double]]]) // Use classOf for Scala

  /** Converts the DataFrame to a 2D double array model matrix with optional
    * intercept.
    *
    * @param df
    *   The DataFrame to convert.
    * @param fillValue
    *   The value to fill NA/null values with.
    * @param addIntercept
    *   Whether to add an intercept column.
    * @tparam V
    *   The type of the values in the DataFrame.
    * @return
    *   A 2D double array.
    */
  def toModelMatrix[V](
      df: DataFrame[V],
      fillValue: Double,
      addIntercept: Boolean,
  ): Array[Array[Double]] =
    toModelMatrixDataFrame(df, null, addIntercept, null, null).fillna(fillValue)
      .toArray(classOf[Array[Array[Double]]]) // Use classOf

  /** Converts the DataFrame to a 2D double array model matrix using a template.
    *
    * @param df
    *   The DataFrame to convert.
    * @param fillValue
    *   The value to fill NA/null values with.
    * @param template
    *   A template DataFrame.
    * @tparam V
    *   The type of the values in the DataFrame.
    * @return
    *   A 2D double array.
    */
  def toModelMatrix[V](
      df: DataFrame[V],
      fillValue: Double,
      template: DataFrame[Object],
  ): Array[Array[Double]] =
    toModelMatrixDataFrame(df, template, false, null, null).fillna(fillValue)
      .toArray(classOf[Array[Array[Double]]]) // Use classOf

  /** Converts the DataFrame to a 2D double array model matrix using a template
    * and optional intercept.
    *
    * @param df
    *   The DataFrame to convert.
    * @param fillValue
    *   The value to fill NA/null values with.
    * @param template
    *   A template DataFrame.
    * @param addIntercept
    *   Whether to add an intercept column.
    * @tparam V
    *   The type of the values in the DataFrame.
    * @return
    *   A 2D double array.
    */
  def toModelMatrix[V](
      df: DataFrame[V],
      fillValue: Double,
      template: DataFrame[Object],
      addIntercept: Boolean,
  ): Array[Array[Double]] =
    toModelMatrixDataFrame(df, template, addIntercept, null, null)
      .fillna(fillValue).toArray(classOf[Array[Array[Double]]]) // Use classOf

  /** Converts the DataFrame to a 2D double array model matrix using a template,
    * optional intercept, and factor references.
    *
    * @param df
    *   The DataFrame to convert.
    * @param fillValue
    *   The value to fill NA/null values with.
    * @param template
    *   A template DataFrame.
    * @param addIntercept
    *   Whether to add an intercept column.
    * @param factorReferences
    *   A Map of reference factors for nominal variables.
    * @tparam V
    *   The type of the values in the DataFrame.
    * @return
    *   A 2D double array.
    */
  def toModelMatrix[V](
      df: DataFrame[V],
      fillValue: Double,
      template: DataFrame[Object],
      addIntercept: Boolean,
      factorReferences: JMap[JString, JString] | Null,
  ): Array[Array[Double]] =
    // Keep factorReferences as Java Map as it's an input parameter
    toModelMatrixDataFrame(df, template, addIntercept, factorReferences, null)
      .fillna(fillValue).toArray(classOf[Array[Array[Double]]]) // Use classOf

  /** Encodes the DataFrame as a model matrix DataFrame.
    *
    * @param df
    *   Dataframe to be converted.
    * @tparam V
    *   The type of the values in the DataFrame.
    * @return
    *   A new DataFrame encoded as a model matrix.
    */
  def toModelMatrixDataFrame[V](df: DataFrame[V]): DataFrame[JNumber] = // Return DataFrame[Number]
    toModelMatrixDataFrame(df, null, false, null, null)

  /** Encodes the DataFrame as a model matrix DataFrame with optional template
    * and intercept.
    *
    * @param df
    *   Dataframe to be converted.
    * @param template
    *   template DataFrame which has already been converted.
    * @param addIntercept
    *   Whether to add an intercept column.
    * @tparam V
    *   The type of the values in the DataFrame.
    * @return
    *   A new DataFrame encoded as a model matrix.
    */
  def toModelMatrixDataFrame[V](
      df: DataFrame[V],
      template: DataFrame[Object] | Null,
      addIntercept: Boolean,
  ): DataFrame[JNumber] = // Return DataFrame[Number]
    toModelMatrixDataFrame(df, template, addIntercept, null, null)

  /** Encodes the DataFrame as a model matrix, converting nominal values to
    * dummy variables and optionally adds an intercept column. In addition it is
    * possible to send in a Map which contains reference categories for all or a
    * subset of the variables. The Map should contain pairs: variable =>
    * reference factor. I.e if you have a column (variable) called "color" and
    * you want "red" to be the reference factor in that column you should put
    * the following in the Map: Map.put("color", "red")
    *
    * @param df
    *   Dataframe to be converted
    * @param template
    *   template DataFrame which has already been converted
    * @param addIntercept
    * @param factorReferences
    *   a Map of reference factor for each variable (null if none)
    * @param naString
    *   replaces null values in DF with this string (default if not supplied is
    *   NA)
    * @return
    *   a new DataFrame encoded as a model matrix
    */
  def toModelMatrixDataFrame[V](
      df: DataFrame[V],
      template: DataFrame[AnyRef] | Null,
      addIntercept: Boolean,
      factorReferences: JMap[String, String] | Null,
      naString: String | Null,
  ): DataFrame[JNumber] = { // Return DataFrame[Number]
    val newDf = new DataFrame[JNumber]() // Create a new DataFrame with Number type

    if (addIntercept) {
      // Add an intercept column
      newDf.add("DFMMAddedIntercept")
      val interceptColumn: ListBuffer[JNumber] = new ListBuffer[JNumber]() // Use Java List for compatibility with DataFrame.append
      for (_ <- 0 until df.length) // Assuming length() is row count
        interceptColumn.append(JDouble.valueOf(1.0)) // Add 1.0 as Double
      newDf.append(interceptColumn.toSeq) // Append the entire column
    }

    // Get column names as Scala List
    val columns: List[Any] = df.getColumns.toList

    // Get column types as Scala List
    val colTypes: List[Class[?]] = df.types.toList // Assuming df.types() returns Java List<Class<?>>

    // Now convert Nominals (String columns) to dummy variables
    // Keep all others as is
    for (columnIdx <- 0 until df.size) { // Assuming size() is column count
      val col = df.col(columnIdx.toInt) // Assuming df.col(index) returns Java List<V>
      val columnName: String = columns(columnIdx).toString

      // Use pattern matching on the column type
      colTypes(columnIdx) match {
        case cls if classOf[JNumber].isAssignableFrom(cls) => // If it's a Number type
          val nums: ListBuffer[JNumber] = new ListBuffer[JNumber]() // Use Java List
          for (num <- col) // Iterate through Java List using asScala
            nums.append(num.asInstanceOf[JNumber]) // Cast to Java Number
          newDf.add(columnName, nums) // Add the column to the new DataFrame

        case cls if classOf[Date].isAssignableFrom(cls) => // If it's a Date type
          val dates: ListBuffer[JNumber] = new ListBuffer[JNumber]() // Use Java List
          for (date <- col) // Iterate through Java List using asScala
            // Convert Date to Double (milliseconds since epoch)
            dates
              .append(JDouble.valueOf(date.asInstanceOf[Date].getTime.toDouble)) // Cast to Date, get time, convert to Double
          newDf.add(columnName, dates) // Add the column

        case cls if classOf[Boolean].isAssignableFrom(cls) => // If it's a Boolean type
          val bools: ListBuffer[JNumber] = new ListBuffer[JNumber]() // Use Java List
          for (tVal <- col) // Iterate through Java List using asScala
            // Convert Boolean to 1.0 or 0.0
            bools.append(
              JDouble.valueOf(if (tVal.asInstanceOf[Boolean]) 1.0 else 0.0),
            ) // Cast to Boolean
          newDf.add(columnName, bools) // Add the column

        case cls if classOf[JString].isAssignableFrom(cls) => // If it's a String type (Nominal)
          // Use mutable.HashSet for namesUsed
          val namesUsed = mutable.HashSet[String]()
          // Get extra column data if template is provided
          val extra: Seq[AnyRef] =
            if (template != null) template.col(columnIdx) else Seq.empty
          // Assuming template.col returns Java List<Object>

          // Call the helper function to convert variable to dummy variables
          val vr = variableToDummy(
            col.toList,
            Option(extra).map(_.toList).orNull,
            columnName,
            Option(factorReferences).map(_.asScala.toMap).orNull,
            naString,
          ) // Convert Java List/Map to Scala List/Map for the call

          val variable: List[List[JNumber]] = vr.col // vr.col is List[List[Number]]
          val names: Array[String] = vr.names // vr.names is String[]

          var cnt = 0
          for (dummyColData <- variable) {
            // Generate dummy variable column name
            val name = columnName + "$" + nameToValidName(names(cnt), namesUsed)
            cnt += 1
            // Add the dummy variable column to the new DataFrame
            newDf.add(name, dummyColData.asJava) // Convert Scala List[Number] to Java List<Number>
          }

        case _ => // For any other type, assume it should be treated as nominal (String)
          // This case handles types not explicitly listed above, treating them like String for dummy variable creation
          val namesUsed = mutable.HashSet[String]()
          val extra: Seq[AnyRef] =
            if (template != null) template.col(columnIdx) else Seq.empty

          val vr = variableToDummy(
            col.toList,
            Option(extra).map(_.toList).orNull,
            columnName,
            Option(factorReferences).map(_.asScala.toMap).orNull,
            naString,
          )

          val variable: List[List[JNumber]] = vr.col
          val names: Array[String] = vr.names

          var cnt = 0
          for (dummyColData <- variable) {
            val name = columnName + "$" + nameToValidName(names(cnt), namesUsed)
            cnt += 1
            newDf.add(name, dummyColData.asJava)
          }
      }
    }

    newDf // Return the new DataFrame
  }

  /** Generates a valid column name for a dummy variable, ensuring uniqueness.
    *
    * @param string
    *   The base string for the name.
    * @param namesUsed
    *   A mutable Set of names already used in the DataFrame.
    * @return
    *   A unique and valid column name.
    */
  protected def nameToValidName(
      string: String,
      namesUsed: mutable.Set[String],
  ): String = {
    // Remove non-alphabetic characters
    var result = string.replaceAll("[^\\p{Alpha}]", "")
    // Apply max length limit if positive
    if (dummyVariableMaxLen > 0)
      result = result.substring(0, Math.min(result.length, dummyVariableMaxLen))

    var tryCnt = 0
    val tmp = result
    // Ensure uniqueness by appending a counter if the name is already used
    while (namesUsed.contains(result)) {
      result = tmp + tryCnt
      tryCnt += 1
    }
    // Add the generated unique name to the set of used names
    namesUsed.add(result)
    result // Return the unique name
  }

  // Define the inner class as a case class for immutability and convenience
  protected case class VariableToDummyResult(
      col: List[List[JNumber]],
      names: Array[String],
  ) // Use JNumber for Number

  /** Converts a single column of nominal values into multiple dummy variable
    * columns.
    *
    * @param colVals
    *   The list of values in the column.
    * @param extra
    *   Optional extra values (from a template) to include in factor levels.
    * @param columnName
    *   The name of the original column.
    * @param references
    *   Optional map of reference factors for columns.
    * @param naString
    *   An optional string representation of NA values.
    * @tparam V
    *   The type of the values in the column.
    * @return
    *   A VariableToDummyResult containing the dummy variable columns and their
    *   names.
    * @throws IllegalArgumentException
    *   if a specified reference factor does not exist in the column.
    */
  // @SuppressWarnings({ "rawtypes", "unchecked" }) // Not needed in Scala
  protected def variableToDummy[V](
      colVals: List[V],
      extra: List[Object] | Null,
      columnName: String,
      references: Map[String, String] | Null,
      naString: String | Null,
  ): VariableToDummyResult = {
    // Use mutable.ListBuffer for building the result list of lists
    val result = mutable.ListBuffer[List[JNumber]]() // Use JNumber for Number
    // Convert column values to String, handling null and NA string
    val col: List[String] = colVals.map(value =>
      if (value == null) if (naString == null) "NA" else naString
      else value.toString,
    )

    // Use immutable.TreeSet to get sorted unique factors
    var factors: TreeSet[String] = TreeSet.empty[String] ++ col // Start with factors from the column
    if (extra != null) factors = factors ++ extra.map(_.toString) // Add factors from extra data

    // Handle reference factor
    val referenceFactor: Option[String] = Option(references)
      .flatMap(_.get(columnName)) // Get reference factor safely
    referenceFactor match {
      case Some(ref) =>
        // If a reference factor is specified, remove it from the factors set
        if (!factors.contains(ref)) throw new IllegalArgumentException(
          s"You specified '$ref' as a reference for '$columnName' but it did not exist in this column",
        )
        factors = factors - ref // Remove the reference factor
      case None =>
        // If no reference factor specified, remove the last factor (alphabetically)
        // This matches the Java code's behavior of removing the last element from the sorted set
        factors.lastOption.foreach { lastFactor =>
          factors = factors - lastFactor
        }
    }

    // Convert the remaining factors into dummy variables
    val names: Array[String] = factors.toArray // Convert the Set of factor names to an Array

    for (v <- factors) { // Iterate through the remaining factors
      // Create a new dummy variable column (List of Numbers)
      val newDummy: mutable.ListBuffer[JNumber] = mutable.ListBuffer[JNumber]() // Use mutable ListBuffer for building the column
      for (value <- col) // Iterate through the original column values (as Strings)
        // Add 1.0 if the value matches the current factor, otherwise add 0.0
        if (value == v) newDummy.append(JDouble.valueOf(1.0)) // Add 1.0 as Double
        else newDummy.append(JDouble.valueOf(0.0)) // Add 0.0 as Double
      result.append(newDummy.toList) // Add the completed dummy column (converted to immutable List) to the result
    }

    // Return the result wrapped in the case class
    VariableToDummyResult(result.toList, names) // Convert the result ListBuffer to immutable List
  }

  /** Creates a new DataFrame indicating which elements are null.
    *
    * @param df
    *   The DataFrame to check.
    * @tparam V
    *   The type of the values in the DataFrame.
    * @return
    *   A new DataFrame of Booleans.
    */
  def isnull[V](df: DataFrame[V]): DataFrame[Boolean] = // Return DataFrame[Boolean]
    df.apply(new Function[V, Boolean]() { // Use Java Boolean
      override def apply(value: V): Boolean = value == null // Check for null
    })

  /** Creates a new DataFrame indicating which elements are not null.
    *
    * @param df
    *   The DataFrame to check.
    * @tparam V
    *   The type of the values in the DataFrame.
    * @return
    *   A new DataFrame of Booleans.
    */
  def notnull[V](df: DataFrame[V]): DataFrame[Boolean] = // Return DataFrame[Boolean]
    df.apply(new Function[V, Boolean]() { // Use Java Boolean
      override def apply(value: V): Boolean = value != null // Check for not null
    })

  // Inner classes for conversions - kept as Java interfaces for compatibility with DataFrame.apply
  private class NAConversion[V](val naString: String | Null)
      extends Function[V, V]:
    override def apply(value: V): V =
      // Check if naString is not null AND the String representation of the value equals naString
      if (naString != null && JString.valueOf(value).equals(naString)) null
        .asInstanceOf[V] // Return null if it matches NA string
      else value // Otherwise return the original value

  private final class StringConversion[V] extends Function[V, JString]: // Return Java String
    override def apply(value: V): JString = JString.valueOf(value) // Convert to Java String

  private final class LongConversion[V] extends Function[V, JLong]: // Return Java Long
    override def apply(value: V): JLong | Null =
      try JLong.valueOf(JString.valueOf(value)) // Convert to String, then parse as Java Long
      catch {
        case ignored: NumberFormatException => null // Return null on failure
      }

  private final class DoubleConversion[V] extends Function[V, JDouble]: // Return Java Double
    override def apply(value: V): JDouble | Null =
      try JDouble.valueOf(JString.valueOf(value)) // Convert to String, then parse as Java Double
      catch {
        case ignored: NumberFormatException => null // Return null on failure
      }

  private final class BooleanConversion[V] extends Function[V, JBoolean]: // Return Java Boolean
    override def apply(value: V): JBoolean | Null = {
      val str = JString.valueOf(value) // Convert to Java String
      if (str.matches("t(r(u(e)?)?)?|y(e(s)?)?")) JBoolean.TRUE // Return Java Boolean.TRUE
      else if (str.matches("f(a(l(s(e)?)?)?)?|n(o)?")) JBoolean.FALSE // Return Java Boolean.FALSE
      else null // Return null on failure
    }

  private final class DateTimeConversion[V] extends Function[V, Date]: // Return Java Date
    // Use Java List for the formats list
    private val formats: JList[DateFormat] = JArrays.asList(
      new SimpleDateFormat("y-M-d'T'HH:mm:ssXXX"),
      new SimpleDateFormat("y-M-d'T'HH:mm:ssZZZ"),
      new SimpleDateFormat("y-M-d"),
      new SimpleDateFormat("y-M-d hh:mm a"),
      new SimpleDateFormat("y-M-d HH:mm"),
      new SimpleDateFormat("y-M-d hh:mm:ss a"),
      new SimpleDateFormat("y-M-d HH:mm:ss"),
      new SimpleDateFormat("y/M/d hh:mm:ss a"),
      new SimpleDateFormat("y/M/d HH:mm:ss"),
      new SimpleDateFormat("y/M/d hh:mm a"),
      new SimpleDateFormat("y/M/d HH:mm"),
      new SimpleDateFormat("dd-MMM-yy hh.mm.ss.SSS a"),
      new SimpleDateFormat("dd-MMM-yy hh.mm.ss.SSSSSSSSS a"),
      new SimpleDateFormat("EEE MMM dd HH:mm:ss zzz yyyy"),
      DateFormat.getDateTimeInstance(),
      new SimpleDateFormat("y/M/d"),
      new SimpleDateFormat("M/d/y hh:mm:ss a"),
      new SimpleDateFormat("M/d/y HH:mm:ss"),
      new SimpleDateFormat("M/d/y hh:mm a"),
      new SimpleDateFormat("M/d/y HH:mm"),
      new SimpleDateFormat("M/d/y"),
      DateFormat.getDateInstance(),
    )

    override def apply(value: V): Date | Null = {
      val source = JString.valueOf(value) // Convert to Java String
      val pp = new ParsePosition(0)
      // Iterate through Java List using asScala
      for (format <- formats.asScala) {
        val dt = format.parse(source, pp)
        if (pp.getIndex == source.length) return dt // Return the parsed Date if successful
        // Reset ParsePosition for the next format
        pp.setIndex(0)
        pp.setErrorIndex(-1)
      }
      null // Return null if no format matched
    }
